{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment and interpolation of inelastic scattering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some required parameters (This section requires editing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the name of the file that you wish to open\n",
    "specfilename = '20151111'\n",
    "# the name of the x column\n",
    "x = 'MCMY'\n",
    "# the name of the detector (y column)\n",
    "y = 'PD21'\n",
    "# the name of the monitor column\n",
    "monitor = 'SRcur'\n",
    "# the scans that you wish to process\n",
    "scans = [108, 110, 112, 114]\n",
    "# the name of the output file that you are going to write\n",
    "output_file_name = '-'.join([specfilename, x, y, monitor]) + '-' + '_'.join([str(scan) for scan in scans])\n",
    "print('output file name is going to be: %s' % output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the kind of interpolation you want to use as a string \n",
    "\n",
    "    'linear'\n",
    "    'nearest'\n",
    "    'zero'\n",
    "    'slinear'\n",
    "    'quadratic\n",
    "    'cubic' \n",
    "    \n",
    "where 'slinear', 'quadratic' and 'cubic' refer to a spline interpolation of first, second or third order) or as an integer specifying the order of the spline interpolator to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpolation_mode = 'linear'\n",
    "# The number to divide the step size by \n",
    "# use a value < 1 for more interpolated points\n",
    "# use a value > 1 for less interpolated points\n",
    "densify_interpolated_axis_factor = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The boring stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some imports that are required for this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit.models import LorentzianModel, LinearModel\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining required objects and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Specfile:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = os.path.abspath(filename)\n",
    "        with open(self.filename, 'r') as f:\n",
    "            scan_data = f.read().split('#S')\n",
    "        scan_data = [section.split('\\n') for section in scan_data]\n",
    "        self.header = scan_data.pop(0)\n",
    "        self.scans = {}\n",
    "        for scan in scan_data:\n",
    "            sid = int(scan[0].split()[0])\n",
    "            self.scans[sid] = Specscan(self, scan)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.scans[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.scans)-1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return (self.scans[sid] for sid in sorted(self.scans.keys()))\n",
    "\n",
    "class Specscan:\n",
    "    def __init__(self, specfile, raw_scan_data):\n",
    "        self.specfile = specfile\n",
    "        self.raw_scan_data = raw_scan_data\n",
    "        header_row = self.raw_scan_data.pop(0).split()\n",
    "        self.scan_id = int(header_row.pop(0))\n",
    "        self.scan_command = header_row.pop(0)\n",
    "        self.scan_args = header_row\n",
    "        for row in self.raw_scan_data:\n",
    "            if row.startswith('#L'):\n",
    "                self.col_names = row.split()[1:]\n",
    "        scan_data = [row.split() for row in self.raw_scan_data \n",
    "                     if not row.startswith('#') if row]\n",
    "        self.scan_data = pd.DataFrame(data=scan_data, columns=self.col_names, dtype=float)\n",
    "    def __repr__(self):\n",
    "        return 'Specfile(\"%s\")[%s]' % (self.specfile.filename, self.scan_id)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.scan_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.scan_data)\n",
    "\n",
    "    def plot(self, column_names=None, x=None):\n",
    "        if x is None:\n",
    "            x = self.scan_data.columns[0]\n",
    "        if column_names is None:\n",
    "            column_names = self.scan_data.columns\n",
    "        ncols = 2\n",
    "        nrows = int(np.ceil(len(column_names)/ncols))\n",
    "        try:\n",
    "            self.ncols\n",
    "            self.nrows\n",
    "        except AttributeError:\n",
    "            self.ncols = 0\n",
    "            self.nrows = 0\n",
    "        if self.ncols != ncols or self.nrows != nrows:\n",
    "            self.ncols, self.nrows = ncols, nrows\n",
    "            self.fig, self.axes = plt.subplots(nrows=nrows,\n",
    "                                               ncols=ncols,\n",
    "                                               figsize=(5*ncols, 2*nrows))\n",
    "        self.arts = {}\n",
    "        for data, ax in zip(column_names, self.axes.ravel()):\n",
    "            ax.cla()\n",
    "            self.arts[data] = ax.plot(self.scan_data[x], self.scan_data[data], label=data)\n",
    "            ax.legend(loc=0)\n",
    "            \n",
    "\n",
    "def fit(x, y, bounds=None):\n",
    "    \"\"\"Fit a lorentzian + linear background to `field` in `scan`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scan : Specscan object\n",
    "    field : The field to fit\n",
    "    bounds : The +/- range to fit the data to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fit : lmfit.model.ModelFit\n",
    "        The results of fitting the data to a linear + lorentzian peak\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> fit = fit_lorentzian(scan.scan_data)\n",
    "    >>> fit.plot()\n",
    "    \"\"\"\n",
    "    lorentzian = LorentzianModel()   \n",
    "    linear = LinearModel()\n",
    "    center = x[np.argmax(y)]\n",
    "    if bounds is None:\n",
    "        lower, upper = 0, len(x)\n",
    "    else:\n",
    "        lower = center - bounds\n",
    "        upper = center + bounds\n",
    "        if lower < 0:\n",
    "            lower = 0\n",
    "        if upper > len(x):\n",
    "            upper = len(x)\n",
    "    bounds = slice(lower, upper)\n",
    "#     print(\"Using bounds = {}\".format(bounds))\n",
    "    y = y[bounds]\n",
    "    x = x[bounds]\n",
    "#     print(\"Using x = {}\".format(x))\n",
    "#     print(\"Using y = {}\".format(y))\n",
    "    lorentzian_params = lorentzian.guess(y, x=x, center=center)\n",
    "    linear_params = linear.guess(y, x=x)\n",
    "    lorentzian_params.update(linear_params)\n",
    "    model = lorentzian + linear\n",
    "    return model.fit(y, x=x, params=lorentzian_params)\n",
    "\n",
    "def plotter(xy):\n",
    "    fig, ax = plt.subplots()\n",
    "    arts = {}\n",
    "    for sid, (xdata, ydata) in zip(scans, xy):\n",
    "        arts[sid] = ax.plot(xdata, ydata, '-o', label=sid)\n",
    "    ax.legend(loc=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The exciting stuff!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the spec file with the Specfile object defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = Specfile(specfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raw data to make sure it looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = [(\n",
    "        f[scan_id].scan_data[x].values,\n",
    "        f[scan_id].scan_data[y].values\n",
    "    ) for scan_id in scans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the plotter helper function defined above\n",
    "plotter(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data by the monitor value defined in the first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized = [(\n",
    "        x, \n",
    "        y / f[scan_id].scan_data[monitor].values\n",
    "    ) for scan_id, (x, y) in zip(scans, raw)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the normalized data to make sure it looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the plotter helper function defined above\n",
    "plotter(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to a linear model plus a lorentzian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fits = [fit(xdata, ydata) for (xdata, ydata) in normalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the fits to make sure they look ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_dict = {'title': 'scan_id: %s' % sid}\n",
    "fig_kws = {'figsize': [15, 15]}\n",
    "for sid, f in zip(scans, fits):\n",
    "    f.plot(numpoints=len(f.data)*10, ax_res_kws=title_dict,\n",
    "           ax_fit_kws=title_dict, fig_kws=fig_kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift the peaks to a zero energy transfer based on the center of the Lorentzian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeroed = [(np.array(f.userkws['x']-f.params['center'], dtype=float), f.data) for f in fits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the shifted peaks to make sure they look ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotter(zeroed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the new axis onto which the data should be interpolated\n",
    "\n",
    "This new axis will be a linear space from the minimum value of all scans to the maximum value of all scans with a step size equal to the average step size between all data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = np.average([np.average(np.diff(x)) for x, y in zeroed])\n",
    "minval = np.min([np.min(x) for x, y in zeroed])\n",
    "maxval = np.max([np.max(x) for x, y in zeroed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff, minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_axis = np.arange(minval, maxval, diff / densify_interpolated_axis_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpolaters = [interp1d(x, y, kind=interpolation_mode, \n",
    "                          bounds_error=False, \n",
    "                          fill_value=np.nan) \n",
    "                 for x, y in zeroed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dict of the interpolated values so it can easily be passed to pandas\n",
    "interpolated = {sid: interpolator(new_axis) \n",
    "          for sid, interpolator in zip(scans, interpolaters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(interpolated, index=new_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the new interpolated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(style='-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just take the straight sum of all data in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sum(axis=1).plot(style='-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, that looks a little weird, let's divide the sum by the number of channels at each x value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.sum(axis=1) / df.count(axis=1)).plot(style='-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmm, that still looks a little strange, lets just sum the channels where they **all** have values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna().sum(axis=1).plot(style='-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna().sum(axis=1).to_csv(output_file_name, encoding='ascii', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that we actually output the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat 20151111-MCMY-PD21-SRcur-108_110_112_114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you are working in the notebook and want to download this data file to your local computer, follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Figure out where that file lives with `!pwd`\n",
    "2. Remember the file name given by: `print(output_file_name)`\n",
    "3. Now that you know where the file lives, go back to the home page of jupyter hub by right clicking on the Jupyter icon in the top-left of this page and selecting \"Open in new tab\"\n",
    "4. Then go to that new tab, navigate to the folder that was shown by `!pwd` and open the file named `output_file_name`, shown above\n",
    "5. Finally, open the file by left-clicking on it.  Once it opens, select File -> Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSX (py3)",
   "language": "",
   "name": "xf23id1-srv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
